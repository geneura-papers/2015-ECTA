\documentclass{llncs}

\usepackage{subfigure}
\usepackage{calc}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{multicol}
\usepackage{pslatex}
\usepackage{hyperref}

\subfigtopskip=0pt
\subfigcapskip=0pt
\subfigbottomskip=0pt

\begin{document}
%\SweaveOpts{concordance=TRUE}
<<setup, cache=FALSE,echo=FALSE,warning=FALSE>>=
#You've got to install all these libraries if you want to compile the paper.
library("ggplot2")
library("RCurl") #To download stuff directly from the GitHub repo
library(e1071) # for skewness and kurtosis
# Now download stuff from noisy-ga repo
made.data <- read.csv(text = getURL("https://raw.githubusercontent.com/JJ/noisy-ga/master/data/MADE/made-data.csv"))
pacman.data <-  read.csv(text = getURL("https://raw.githubusercontent.com/JJ/noisy-ga/master/data/ms-pacman/pacman-fitness.csv"))
planetwars.data <- read.csv(text = getURL("https://raw.githubusercontent.com/JJ/noisy-ga/master/data/planet-wars/planetwars-fitness.csv"))
#Or from this same repo
starcraft.data <- read.csv("../data/starcraftdata/starcraft-data.csv")
mlp.data <- read.csv("../data/MLP/data-mlp.csv")
@ 


\title{The Uncertainty Quandary: A Study in the Context of the
  Evolutionary Optimization in Games and other Uncertain Environments}

\author{Juan J. Merelo\inst{1} \and 
    Federico Liberatore\inst{1},
    Antonio Fern{\'a}ndez Ares\inst{1} \and 
    Rub{\'e}n Garc{\'i}a\inst{2} \and 
    Zeineb Chelly\inst{3} \and 
    Carlos Cotta\inst{4} \and 
    Nuria Rico\inst{5} \and 
    Antonio M. Mora\inst{1} \and
    Pablo Garc{\'i}a-S{\'a}nchez\inst{1} \and
    Alberto Tonda\inst{6} \and
    Paloma de las Cuevas\inst{1} \and 
    Pedro A. Castillo\inst{1}}

\institute{Depto. ATC, University of Granada, Spain\\
\email{\tt jmerelo@geneura.ugr.es} \and
Escuela de Doctorado, University of Granada, Spain \and
Lab. LARODEC, Institut Sup\'erieur de Gestion, Tunisia \and
Depto. LCC, University of M{\'a}laga, Spain \and
Depto. EIO, University of Granada, Spain \and
UMR 782 GMPA, INRA, Thiverval-Grignon, France
}

\maketitle 

\begin{abstract}

  In many optimization processes, the fitness or the considered
measure of goodness for the candidate solutions presents
\textit{uncertainty}, that is, it yields different values when
repeatedly measured, due to the nature of the evaluation process or
the solution itself. This happens quite often in the context of
computational intelligence in games, when either bots behave
stochastically, or the target game possesses intrinsic random
elements, but it shows up also in other problems as long as there is
some random component.  Thus, it is important to examine the
statistical behavior of repeated measurements of performance and, more
specifically, the statistical distribution that better fits them. This
work analyzes four different problems related to computational
intelligence in videogames, where Evolutionary Computation methods
have been applied, and the evaluation of each individual is performed
by playing the game, and compares it to other problem, neural network
optimization, where performance is also a statistical variable.  In
order to find possible patterns in the statistical behavior of the variables,
we track the main features of its distributions, \textit{skewness} and
\textit{kurtosis}. Contrary to the usual assumption in this kind of
problems, we prove that, in general, the values of two features imply
that fitness values do not follow a normal distribution; they do
present a certain common behavior that changes as evolution proceeds,
getting in some cases closer to the standard distribution and in
others drifting apart from it. A clear behavior in this case cannot be
concluded, other than the fact that the statistical distribution that
fitness variables follow is affected by selection in different
directions, that parameters vary in a single generation across them,
and that, in general, this kind of behavior will have to be taken into
account to adequately address uncertainty in fitness in evolutionary
algorithms.
\end{abstract}


% ******************************************************************************

\section{Introduction}
\label{sec:introduction}

Optimization methods usually need a single-valued and reliable
feedback to work correctly. This value, usually called {\em cost} or
{\em fitness}, informs the algorithm on the goodness of the solution
and, when facing different alternatives, it is used to select a
particular solution over others. This does not imply the necessity of
a single floating point number as feedback; since these methodology
are based on comparisons, it is usually enough if the values can be
partially ordered. In multiobjective optimization \cite{Deb2001}, for
instance, two solutions can even be considered {\em non-comparable},
based on the set of fitness values they possess.  In either case, the
answer to the question ``Is this solution better than the other?''
needs to be either a `Yes', or `No', or `Not decidable'.


In many cases, however, the fitness or cost of a solution cannot be
described by a scalar value, because there is  \textit{uncertainty} in the measure. 
Such uncertainty is inherent to most real-world physical systems, such as the one described in \cite{esann94}, where a
control system is optimized through a stochastic procedure. 
In these cases, the best way to describe a solution will be a random
variable, not a single value or a vector of deterministic values.
In our research, we routinely find this phenomenon in different
optimization problems, such as:
\begin{itemize}
  \item Optimizing the layout of a web-page using Simulated
  Annealing (SA) \cite{jj-ppsn98}. Since SA is a stochastic procedure, the fitness  of an obtained solution will be a random variable.
  %PABLO: at a first glance I thought each solutions had stochastic fitness, but it is the value of the 'obtained' final solution, so I moved "obtained".
\item training any kind of neural network
  \cite{esann94,merelo:ESNN}; in the second case we dealt with a
  physical installation, introducing another kind of randomness. Since
  training a neural network is usually a stochastic procedure, the error rate
  obtained after every training run will also follow  a statistical
  distribution. 
\item Evolving game bots (autonomous agents) \cite{bots:evostar}. In this case, the
  uncertainty arises from the problem itself; in games, several
  factors such as the initial positions of the players or the
  opponent's behavior add further stochastic components, so that the final
  score will also be {\em uncertain} or {\em noisy}. In some cases,
  too, the bot itself will rely on probabilities to 
  generate its behavior \cite{EvoStar2014:CoEvolutionary}, in which
  case two different runs with exactly the same initial conditions and
  opponent will also yield different scores.
  \item In coevolutionary algorithms \cite{paredis1995coevolutionary},
    individuals are evaluated by randomly choosing opponents from a
    pool, thus resulting in a fitness that is variable in a single
    generation and across generations \cite{DBLP:journals/jcst/MoraFGGF12}.
\end{itemize}

In all these examples, it cannot be said that there is actually {\em noise} added to
a {\em real} fitness. Instead, the fitness itself can be represented with a statistical variable,
whose value arises from a stochastic process, evaluation, or
training. 

%The main issue we try to solve in this problem is the lack
%of an exhaustive research on the behavior of fitness as a random variable.
Despite a considerable amount of literature on problems with stochastic fitness values, there is a distinct lack of exhaustive research on the behavior of fitness functions, seen as random variables.
That is why, after an initial study of noise in a specific game in
\cite{merelo14:noisy}, 
%where our findings indicated that, in some cases, noise followed a
%Gamma distribution, that
%is, a skewed normal distribution and proposing a solution to this using
%Wilcoxon comparison \ref{wilcoxon:1945} as a selection operator, 
we dug into data discovering that, even if the distribution in that
particular case was always a Gamma, the parameters of the distribution
were different. In that study, we proposed a solution to the noise issue, based on using the Wilcoxon comparison \cite{wilcoxon:1945} as a selection operator.
This meant that the random variable behaved in different ways
depending on the particular individual, the state of evolution and, of
course, the specific problem.

But, more importantly, this initial conclusion disagrees with the usual assumptions of
optimization in uncertain environments, where it is usual to take a normal distribution of noise with fixed $\sigma$ as the initial hypothesis \cite{arnold2001evolution}. For instance, in the functions of the Black Box
Optimization Benchmarks \cite{hansen2009real}, uncertainty was
simulated by adding a Cauchy noise function centered in 0,
that is, a centered, sharp bell-shaped distribution,
with different widths. Either multiplicative or additive noise has
been used in different occasions. However, our initial work hints
that this is not the case in real-world optimization problems, 
ultimately invalidating the generality of the conclusions 
on different optimization methods
obtained through the usual benchmarks.
%rendering
%the conclusions achieved on the goodness of one or other method not
%applicable. 
Besides, we also prove in \cite{merelo14:noisy} that,
depending on the shape of the statistical distribution of the fitness,
different methods could yield the best results. While methods that
use the median or average would work well in centered distributions,
other methods such as our technique, based on the Wilcoxon test, are better
in more uncertain environments or, of course, in the case the
noise distribution is not centered. 

In this paper, we collect data from several different
case studies, which will be presented later on, to find a stochastic model
for the fitness using statistical 
tools. Our final objective is to eventually build a model as general
as possible, able to account for most sources of
uncertainty; failing that, to devise selection operators that %PABLO: paloma told me in the mail that this "failing that" is weird. Other option?
% not really. Tell Paloma to change it here - JJ
are able to work with random fitness in a natural way. 
%However, this
%is not the focus of this paper and, if it is eventually needed, is
%left as future work.
This second part, if needed, will be the focus of future research.

The rest of the paper is organized as follows. In Section \ref{sec:soa} we present the
state of the art for evolutionary algorithms in uncertain environments,
to be followed by a short presentation of the four problems with
uncertainty whose measures will be used in this paper in Section
\ref{sec:problems}. Results will be presented in Section
\ref{sec:res}, followed by our conclusions.

% ******************************************************************************

\section{State of the Art}
\label{sec:soa}

\sloppypar The most comprehensive, although not recent, review of the state of the art for 
evolutionary algorithms in {\em uncertain} environments 
is presented by Jin and Branke in \cite{Jin2005303}, while more novel
papers such as \cite{DBLP:journals/corr/QianYZ13,6931307} and
\cite{Qian:sampling} include brief updates. Goh and Tan \cite{goh2007investigation} performed a similar survey, focused on
multiobjective optimization.
% Alberto - the phrase below is IMHO useless
%Increasingly more papers are concerned
%with this type of optimization, so this makes more interesting any
%advance in this field. 
% right - JJ

In their survey, Jin and Branke state that uncertainty is categorized into noise, %Pablo: Paloma suggested connect this paragraph, I added "For example", sounds right?
%Alberto - nah, I think it kind of follows from above
robustness issues, fitness approximation, and time-varying fitness
functions. In addition, different options for dealing with the uncertainty are
discussed. In principle, the 
approach presented in this paper is designed to model the first kind of
uncertainty, namely, noise or uncertainty in fitness evaluation. It
can be argued that there is uncertainty in the true fitness as
stated in the third 
category. However, we think that, in general,
the third issue refers to the case in which expensive fitness
functions are replaced by surrogate functions which carry a certain
amount of error, and whose value varies as the surrogate models are
updated. Independently from the origin of uncertainty, Jin and Branke suggest
several methods to tackle it, based either on {\em implicit} / explicit 
averaging over fitness measures \cite{hansen2009method,esteban2015implicit} 
or on a threshold imposed during the selection phase. Papers such as Stroud's
\cite{stroud2001kalman}, Esteban-D{\'i}az's \cite{esteban2015implicit} or Di Mario's \cite{di2015distributed} use
this kind of approach to deal with noise. 
% [Pedro]Â Add here the reference to the work by Flores2011
Other authors \cite{Flores2011} propose to use new rank-based
selection  and mutation operators in order to evolve a neural network topology
used as a controller for a robot. Results show that those operators are 
suitable for problems where the fitness landscape is noisy, but it is
still using a central value for the fitness that might not be always
valid. 

Since then, several other solutions for uncertainty have
been proposed. A usual approach for scientists more focused
on obtaining a straightforward solution to the optimization problem without
%not concerned not on solving the problem of noise, but on
%a straightforward solution of the optimization problem without
modifying existing tools and methodologies, is
just to disregard the noise in the fitness and take whatever  %[Pedro] I don't understand this sentence. What's is the subject for "use" in this sentence? (check the correspondence).
% take, as in using it as the real fitness.
value is returned by a single evaluation, often after re-evaluating all individuals at each
generation. This option seems to work especially well if the population is
large \cite{hansen2009method}, since the selective pressure is lower
and solutions have the chance to be evaluated several times before
being selected or discarded; this leads, if the population is large
enough, to an {\em implicit averaging} as mentioned in
\cite{Jin2005303}; in fact, Rattray and Shapiro
\cite{rattray1998noisy} in their theoretical model compute by how much
the {\em crisp} population must be enlarged to overcome the {\em
  problem} of noise.
This solution is exploited in our previous research in
games, although one evaluation in some of these works consists, in
  fact, of an average of several evaluations, on different maps or
  considering different opponents, see for instance 
  \cite{bots:evostar,DBLP:journals/jcst/MoraFGGF12,liberatore:pacman},  
or in the evolution of neural networks \cite{castilloGECCO99,merelo:ESNN}. 

The key to the efficiency of this approach stems from the fact that
selection used in evolutionary algorithms 
is usually stochastic, so uncertainty in fitness evaluation
could have the same effect as randomness in selection or a higher mutation
rate, which might make the evolutionary process easier 
in some particular cases
\cite{DBLP:journals/corr/QianYZ13}. 
In fact, Miller and Goldberg proved that an infinite population would not
be affected by noise \cite{miller1996genetic} and Jun-Hua and Ming studied the
effect of noise in convergence rates \cite{Junhua20136780}, proving
that an elitist genetic algorithm finds at least one solution in noisy
environments with probability one,
% Alberto - "finds at least one solution"? What does it mean?
% beats me. I'll have to check out the paper - JJ
% Checked it out. It says exactly that. - JJ
% Alberto - uh...but is the solution a global optimum, a local optimum...?
although with a lowered convergence rate. This possible positive
effect of uncertainty in evaluation leads to some authors calling it
``a blessing and the curse'' in the context of surrogate models
\cite{ong2006curse}, which, as we have seen before, carry with them a degree of
uncertainty and randomness. 

In real-world problems, however, populations are finite: in fact, using large populations
decreases the algorithm's efficiency and can be time consuming, so the usual approach for dealing with
fitness with a degree of randomness is to enlarge the population
to a value bigger than would normally be needed in a non-noisy environment, while keeping it to a manageable size.   
Furthermore, it has been recently proved that using two parents to
generate offspring, that is, crossover, 
is able to successfully deal  with noise \cite{2015arXiv150202793F}, while an
evolutionary algorithm based mainly on mutation,
such as the $\mu$+1 EA, or evolutionary programming \cite{Fogel1966}, 
would suffer a considerable degradation of performance. 
However, crossover is part of the standard kit of evolutionary
algorithms, so using it and increasing the population size has the
advantage that no special provision or change in the implementation
has to be made. %just different values of the standard parameters;
There is no big decreasing in efficiency as long as oversized
populations are not used. Using oversized populations, however, might
have a good effect on the algorithm in general, if appropriate computational resources are available \cite{DBLP:conf/lion/LaredoDFGB13}. 

%Besides using implicit averaging with oversized populations, another
Another way to deal with uncertainty which is
more theoretically sound is using {\em real} averaging, that is, 
% Alberto - the part that begins with "a statistical central tendency" is not very clear, what do we want to tell the reader?
a statistical central tendency
indicator, which usually is  the {\em average}; average happens to be
equal to the median in the case of the random variable following the
normal distribution. In this case, resampling is used to acquire a
statistically significant amount of measures and then the average is
computed over them. 
This strategy has been called
{\em explicit averaging} by Jin and Branke, and it is used, for instance,
in \cite{Junhua20136780}. Explicit averaging decreases the fitness variance,
thus reducing uncertainty, but defining the appropriate sample size for the averaging
process is not straightforward \cite{aizawa1994scheduling};
%the problem is that it is not clear in advance what would be the
%sample size used for averaging \cite{aizawa1994scheduling} and,
besides, this central tendency might not be representative % Alberto - of what?
if the
noise is not centrally distributed, as proved in \cite{merelo2016statistical}.
Our research group uses this approach in some cases, with an important difference: 
individuals are not re-evaluated every additional generation, but
their fitness value is the average of several evaluations, performed immediately \cite{DBLP:journals/jcst/MoraFGGF12}. 
Most authors use several measures of fitness for each new individual
\cite{costa2013using}, although other averaging strategies have also
been proposed, for example averaging over the neighbourhood of the
individual or using {\em resampling}, that is, heuristically requiring more fitness measurements
%more measures of fitness in a
%number which is decided heuristically
\cite{liu2014mathematically}. This assumes that there is, effectively,
a real average of the 
fitness values, which is true for Gaussian random noise and other
distributions (such as Gamma's or Cauchy's), but it does not
necessarily hold for all distributions. In this paper, we are
going to model these distributions in order to verify whether this
assumption is indeed correct. 

% Alberto - now, in this paragraph below and in the one before, we talk about resampling, but every time it gives me the impression it was supposed to be the first time (or maybe the only time)
% Can't understand you here - JJ
% Alberto - basically, we are re-explaining what resampling is, multiple times.
To the best of our knowledge, 
other central tendency measures such as the median, which might be more adequate for 
certain noise models, %but which is the same for the normal
%distribution usually attributed to noise, 
have not been tested; the median always exists,
while the average might not exist for non-centrally distributed
variables. Besides, most models keep the number of evaluations fixed 
and independent of its value, % Alberto - which value? The fitness value?
which might result in bad individuals
being evaluated multiple times before finally being discarded; some authors have
proposed {\em resampling},
\cite{RadaVilela2014,6900521},
which will effectively increase the number of
evaluations and thus slow down the search. In any case, using explicit averaging usually requires just a small change to the algorithm framework, by
using the average of several evaluations as the new fitness function.
Thus, it is usually the method preferred by researchers and practitioners using off-the-shelf
libraries such as ECJ\cite{luke2006ecj}.

In order to improve the efficiency of the algorithm, or the running
time, these two averaging approaches that are focused on the evaluation process might
be complemented with changes to the selection process. For instance,
a threshold \cite{Rudolph2001318,6900521} that is related to the noise characteristics to
avoid making comparisons of individuals that might, in fact, be very
similar or statistically the same; this is usually called {\em
  threshold selection} and can be applied either to explicit or
implicit averaging fitness functions. 
% Alberto - I don't understand the phrases below, until the end of the paragraph. "The algorithms used for solution"? Also, is it not re-sampling all over again?
Uncertainty can also be used to compare different algorithms, with some authors proposing,
instead of taking more measures,   
testing different solvers \cite{cauwet2014algorithm}, some of which
might be more affected by noise than others. However, recent papers
have proved that sampling might be ineffective \cite{Qian:sampling} in
some types of evolutionary algorithms, adding running time without an
additional benefit in terms of performance. This is one lead we will
try to follow in the current paper, by modeling noise in order to
eventually design an algorithm that behaves correctly in that environment.
% Is this better? - JJ
% Alberto - Much better!

All the aforementioned approaches still face the issue of the statistical
representation of the {\em true} fitness, even more so if there are instead
several measures that represent, {\em as a set}
the fitness of an individual, such as the case study described 
in \cite{merelo2016statistical}. This is what
we have been using in many of our papers: a method that uses resampling via an
 memory attached to every individual that stores all fitness measures % Alberto - what is "an individual memory"?
 % all fitness measurements - JJ
and uses either explicit averaging or statistical
tests like the non-parametric Wilcoxon test. 
In order to test this approach on benchmark problems
more realistic that the ones adopted so far, we need
to characterize the noise that
actually appears in games and other real-world case studies for optimization. 

% ******************************************************************************

\section{Case studies used in this paper}
\label{sec:problems}

% Antonio - reescribo el texto para cambiar el orden
The fitness of four different case studies, all related to
computational intelligence in games, are described in this paper:
generation of character backstories in artificial worlds, described in
subsection \ref{ss:made}, optimization of bots for playing the real
time strategy game (RTS) Planet Wars in \ref{ss:pw}, optimization of
the ghost team in Ms. Pac-Man, which will be described in subsection
\ref{ss:pacman}, automatic generation of autonomous players for the
famous RTS StarCraft, explained in subsection \ref{ss:starcraft} and
an artificial neural network optimization problem using an EA
\ref{ss:gprop}.  

These five problems have been chosen for two main
reasons: the origin of uncertainty is different for each of the case
studies; and data for the experiments is readily available, with the
possibility of running further experimental trials, if needed.  In the
case of MADE, fitness is computed through a simulation; in the case of
Planet Wars, the bot themselves have a random component, with its
representation including probabilities of different courses of action;
in Ms. Pac-Man, uncertainty lies in the nature of the game itself; and
the huge amount of possibilities in StarCraft, with a considerable
number of units behaving independently, creates an extremely high
source of uncertainty. These scenarios are not a complete
representation of all possible causes of uncertainty in optimization,
but we think that the sample is big and varied enough to generalize
the obtained results, which will be presented in the next section.

In all cases, three generations were chosen, and they are different
depending on the problem. We feature the first generation (except in
the case of MADE), a intermediate generation and one close to the
end of the evolution, containing individuals close to the
solution. These were chosen to check the progress of the two
statistical parameters in different situations: close to random in the
case of the first generations, and close to the {\em real} value, in
the case of the last ones. The particular number of generations is not
really important, the importance is how close they are to the end of
the evolution, which is different in each case. 

We will next examine the creation of character backstories in the
problem called MADE.

%---------------------------------------------------------

\subsection{Creation of character backstories}
\label{ss:made}

MADE (MAssive Drama Engine for non-player characters)
\cite{garcia14my} is a framework for the automatic generation of
virtual worlds that allow the emergence of backstories for secondary
characters that can later on be included in videogames. In this context, an {\em archetype}
is a well-known behaviour present in the imaginary collective (for
example, a ``hero'' or a ``villain''). Given a fitness that takes into account the
existence of different $N_a$ archetypes for a virtual world, MADE uses
a genetic algorithm to optimize the parameter values of a Finite State
Machine (FSM) that models the agents of that world. For the evaluation,
a world is simulated using this parameter set, and the log is analyzed
to detect behaviours of the world agents that match the desired
archetypes. 

As the evolved parameters are the probabilities to jump from one state
to another in the FSM, each fitness evaluation is performed executing
the virtual world five times per individual, obtaining the average
fitness. Selection is, therefore, performed comparing this average
fitness, with a binary tournament. Fitness values range
from 0 to $N_a$, and are calculated taking into account the rate of occurrence of the archetypes in the execution log. 

%---------------------------------------------------------

\subsection{A `simple' real-time strategy game: Planet Wars}
\label{ss:pw}

Planet Wars \cite{DBLP:conf/cec/Fernandez-AresMGGF11} is a
simple Real-Time strategy (RTS) game. In RTS games, 
%are not turn-based and their objective 
the objective is to defeat the enemy using resources available in
the map to build and manage units and structures: differently from turn-based
strategy games, in RTS all choices have to be performed in real time.

%Computational intelligence
%methods have been applied to 
Planet Wars provides a
simplification of the usual elements in RTS games: one kind of unit
(spaceships) and one kind of resources and structures
(planets). Spaceships are automatically generated on the planets controlled by a player,
and they are used to conquer enemy planets, the main way to defeat the enemy.
%as this is the objective of the game. 

In this paper we are % Alberto - which paper? The current, or the Planet Wars one?
%this one - JJ
using the results obtained from the Genebot algorithm \cite{EvoStar2014:GPBot}. This
algorithm optimizes the parameters of a hand-coded FSM that indicates how many ships send from each
planet to attack or reinforce another planet depending of some other values (such as the distance between planets). The generated bot is not
deterministic, as some of the jumps of the states are based on
probabilities. 
Fitness is calculated confronting five times the bot obtained from the parameter set of the FSM against
a competitive hand-coded bot. The result of each match takes into account the `slope' of the number of player spaceships
during the time of the match. Positive results mean that the bot won,
as the slope will be positive, and vice versa. Theoretical values are
in the range $[-1,1]$, although these values are impossible to attain
in the game. A value of -1 would indicate that the player lost all
their ships in the initial time, while $1$ would mean the contrary: it
generated all the spaceships and won in the initial time. The fitness
of an individual is the sum of all five results, and therefore being
in the range $[-5,5]$. This fitness measurement is explained in more detail
in \cite{Fernandez-Ares_COSECIVI14}.  

%---------------------------------------------------------

% Alberto - for the Ms. Pac-Man case study, the structure of an individual is not explained at all, maybe it should be added?
% Don't know if its worth the while. We are only concerned with the
% fact that the fitness behaves that way - JJ
% Alberto - but it could be useful to the reader, just to know whether it's a fixed-length vector of real values, or something more complex.
% Beats me. I think it is just score. Will have to read over again the
% paper, and there's no time - JJ

\subsection{Ghost team optimization}
\label{ss:pacman}

Ms. Pac-Man is a variant of the famous Pac-Man game that extends its
mechanics with several extra features, the most interesting being
the inclusion of a random event that
reverses the direction of the ghosts. This game is used in 
the Ms. Pac-Man vs Ghosts competition \cite{Lucas2009}, where participants can submit
controllers for both Ms. Pac-Man and the Ghost Team, the first trying
to maximize its score, the second trying to minimize Ms. Pac-Man's. 
The framework used to test the methodology analyzed defines the
following restrictions for the Ghost Team: 
\begin{itemize}
 \item A ghost can never stop and if it is in a corridor it must move forward.
 \item A ghost can choose its direction only at a junction.
 \item Every time a ghost is at a junction the controller has to provide a direction from a set of feasible directions.
 \item After 4000 game ticks, a level is considered completed and the game moves on to the next one.
\end{itemize} 

In the methodology applied to this case study, published in \cite{liberatore:pacman}, the fitness of each individual is computed as the maximum
score obtained by eight different Ms. Pac-Man controllers. Some of these controllers are the champions of
past editions of the international competition, so they are very
tough rivals for the ghost team.

%---------------------------------------------------------

\subsection{A complex real-time strategy game: StarCraft}
\label{ss:starcraft}

StarCraft has become a {\em de facto} testbed for AI research in
complex RTS games \cite{OntanonSURCP13}. In fact, given the high
variety of game features, such as configuration options, game modes,
units, maps, etc; along with the existence of several frameworks and
tools related with it; researchers have exploited the game for a great
variety of topics: micro and macro management of units, temporal and
spatial reasoning, battle planning, combat results prediction, optimal
paths and dealing with problems such as the one that is the topic of
this paper, uncertainty in the evaluation of the fitness, among others. % Alberto - what is
                                        % "uncertainty addressing" in
                                        % this context? 
%Added, although I didn't write this - JJ
%Pablo: it was referred to the "fog of war" thing, but as you have 
%rewritten to match with the paper topic let keep it as it is now.

The individuals described in this subsection have been generated using
StarCraftGP \cite{Garcia15StarcraftGP}, a Genetic Programming (GP)
\cite{Koza93} framework that automatically generates the source code of
high-level strategies of bots. As in some of the games described
above, the fitness of one individual is computed pitting the bot
against different enemies, each one following a different strategy.  
More specifically, in this case every individual faces three {\em
  divisions} of enemies (considered as weak, medium and strong rivals),
each division containing four different enemies.  
% Antonio - are they 'different' as I have written?
% Alberto - Yes, you have 4 different bots in each tier, for a total of 12 bots


The original fitness function assigned a higher weight to a victory 
against the stronger enemies, i.e. it used a lexicographical fitness, 
so one victory in a higher tier 
was considered better than more victories in the immediately lower one. 
For example, one individual that wins 1 time against one enemy of 
every tier was considered better than one individual that beats all
 individuals from medium and weak tier, but none in the strong one.

% Antonio - Check my rephrasing and please try to clarify this giving a more complete explanation. Is the paragrpah below explaining this? ;) Pablo: fixed and explained below again

Conversely, to ease comparisons among noise in the present study, we
have calculated an aggregated fitness function that still respects
this decision, that is, prioritizing victories of harder divisions,  
% Antonio - Which decision do you refer to? Pablo: explained
by giving different weights to each one. The following equation
describes the fitness function: 
\begin{equation}
F_{StarCraft}=21\times A + 5\times B + C + R
\end{equation}

Where $A$ is the number of victories against enemies in the strongest
tier, $B$ is the number of victories against the middle tier, and $C$
is the number of victories against the weakest enemies. Thus, for
example, one victory in the middle tier is worth more points (5
points) than 4 victories in the weak tier (4 points). Also, a
coefficient of the aggregated score at the end of all the games, $R$
has been added, in order to deal with ties in number of
victories. This is in fact an internal score computed by the game,
that takes into account all the aspects of a match, ranging from the
number of kills to the type and quality of units built.  
% Antonio - Please, explain this better. ;) Pablo: Done

Moreover, the evaluation process is quite time-consuming, so, in order
to save execution time, at least one enemy of the weak tiers must be
defeated before allowing the individual to proceed to fight the next one. To
this end, if a bot does not win against weaker rivals, we consider it
cannot defeat the stronger ones: so, the evaluation terminates at that
point, with the current score. 
% Antonio - with the current score, right? Pablo: yes, yes.


%---------------------------------------------------------
% Alberto - here, you should probably explain better the structure of an individual and the characteristics of the fitness function...right?
% Please, Alberto, do it yourself - JJ
% Alberto - I was referring to the Artificial Neural Networks project (below), to which I did not participate, and of which I know nothing about :-)
% Don't know much either, this was written by Pedro - JJ
\subsection{Artificial Neural Networks Optimization Using an EA: GProp}
\label{ss:gprop}

%Designing an artificial neural network is not an easy process, as 
%it requires setting a layer structure with connections among the different 
%components, tuning several parameters, such as the initial weights, 
%and defining a set of learning constants. Then, a training method must be used, 
%which is usually an iterative gradient descent algorithm. 
% Man, I wrote that sentence like 20 years ago. You should have
% changed it already - JJ

The design of an Artificial Neural Network (ANN) \cite{Haykin98_NNC} requires to set both, the structure of its set of hidden layers, along with the parameters it uses (weights and learning constants).
% Antonio - I have rewritten it.

G-Prop (``genetic backpropagation'') \cite{CastilloNPL,castilloNC,ieeeanova2002} 
aims to solve the problem of finding 
appropriate initial weights and learning parameters for a single hidden layer 
of a Multilayer Perceptron (MLP), by combining an EA and QuickProp method \cite{FahlmanQP}. 
The EA selects the MLP's initial weights, picks its learning rate, and changes the 
number of neurons in the hidden layer through the application of
specific genetic operators. 

G-Prop is a hybrid algorithm that leverages the capabilities of two classes 
of algorithms: the ability of the EA to find a solution close to the global 
optimum, and the ability of the QuickProp algorithm to tune a solution and reach 
the nearest local minimum by means of a local search performed from the 
solution found by the EA.

In this case, training is not deterministic and results in different
models, the success rate, which is used as a fitness value, achieved during test will be different for
each training run. This uncertainty makes this method amenable to
analysis in the paper.


% ******************************************************************************

\section{Experiments and Results}
\label{sec:res}

With the case studies presented above, data on fitness values is collected by
selecting a few random individuals in every generation of the considered EAs,
and measuring
their fitness 100 times, intentionally using much more repetitions than a normal optimization method would. Thus, every individual is represented by a
random variable sampled 100 times. % Alberto - can we replace "with the 100 measures taken with its fitness" with "sampled 100 times"? Would it make sense?
% Done. Thanks - JJ
According to the usual assumptions, this random variable
should follow a normal distribution, with a certain $\sigma$
and centered on the {\em true} fitness value. In order to verify this
hypothesis, we plotted the distribution's {\em skewness}, that is, its
asymmetry, and its {\em kurtosis}, which is a parameter related to its
shape \cite{groeneveld1984measuring}
% Alberto - is there a reference for skewness and kurtosis?
% Added citation - JJ
A symmetrical distribution, like the normal
distribution, has skewness and kurtosis equal to 0; asymmetric
distributions, such as the Gamma that we had found in previous papers
\cite{merelo14:noisy}, have non-zero skewness and kurtosis,
related to their $\theta$ and $\kappa$ parameters, for instance. These
parameters are what defines the statistical distribution; $\kappa$ is
the shape parameter and skewness is $2/\sqrt{\kappa}$, which means
that it is only 0, corresponding to normality, if $\kappa$ is too
big. Kurtosis is $6/\kappa$, implying the same. 
% Alberto - yes, but what are \alpha and \kappa? They are introduced here, but not explained
A random variable can have skewness and kurtosis fixed at any value: thus, we present
these values in the following figures, with skewness
plotted as the $x$ axis against kurtosis on the $y$ axis.

\begin{figure}[htb]
  \centering
<<made,cache=FALSE,echo=FALSE,warning=FALSE>>=
s.k <- data.frame(Gen=character(), 
                  Skewness=character(),
                  Kurtosis=character(),
                  stringsAsFactors=FALSE)

for ( i in c(64,128,256)) {
    for ( j in unique(subset(made.data,Gen==i)$ID) ) {
        this.data <- subset(made.data,Gen==i & ID==j)$Fitness
        s.k <- rbind( s.k
                     , data.frame(Gen=paste("Gen",i)
                                  ,Skewness=skewness(this.data)
                                  ,Kurtosis=kurtosis(this.data)))
    }
}

ggplot(s.k,aes(x=Skewness,y=Kurtosis,color=Gen))+geom_point(aes(shape=Gen))+scale_x_continuous(limits=c(-1,2.5))+scale_y_continuous(limits=c(-1,8))+theme_bw()

@ 
\caption{Skewness and kurtosis for fitness in several generations of
  the MADE problem. Different colors represent different generations.}
\label{fig:made}
\end{figure}

% Antonio - yo cambiar?a los s?mbolos de cada serie de datos. Es dif?cil distinguirlas en las gr?ficas.

Figure \ref{fig:made} represents skewness and kurtosis in the MADE case study, 
for which
we took measures of a variable amount of individuals every
generation, from 100 in generation 64 to around 50 in the latest
generation. The number was variable because some of them stopped
before finishing. Anyway, the number of measurements is enough for the
statistical analysis.
% Alberto - ok, but why? Why didn't you take 50 individuals in every generation?
% It takes a good while to do so - JJ
% Alberto - I see; but this is a weak point that some reviewers might dislike...
% We'll have to make do as long as it is statistically significant.
You can already see that the distribution is not normal, since almost
no individual has a kurtosis and skewness equal to zero; some of them,
however, are close. This will be
the case for the rest of the experiments, too; in some very limited
cases fitness distribution will be almost normal in the first or the
last generations, but that will never be the case for all individuals
or even a significant fraction, nullifying the hypothesis of fitness
behaving like a crisp fitness with gaussian added noise.
As generations proceed, a curious convergence towards the normal
distribution is observed; in the first
generations, values of skewness and kurtosis are quite high and
correspond to an arbitrary distribution (Beta or uniform): however, as
the simulation proceeds, the two values approach zero. It must be noted, however, 
that they do not
converge exactly to 0, meaning that, even if uncertainty in this case can be
approached by a normal distribution, such an approximation would only be
correct for the latest generations of the simulation. In general, individual
fitness in MADE will follow an arbitrary distribution with a general shape and
asymmetry. 

\begin{figure}[htb]
  \centering
<<planetwars,cache=FALSE,echo=FALSE,warning=FALSE>>=
pw.s.k <- data.frame(Gen=character(), 
                  Skewness=character(),
                  Kurtosis=character(),
                  stringsAsFactors=FALSE)

for ( i in c(1,50)) {
    for ( j in unique(subset(planetwars.data,Gen==i)$ID) ) {
        this.data <- subset(planetwars.data,Gen==i & ID==j)$Fitness
        pw.s.k <- rbind( pw.s.k
                     , data.frame(Gen=paste("Gen",i)
                                  , Skewness=skewness(this.data)
                                  , Kurtosis=kurtosis(this.data)))
    }
}

ggplot(pw.s.k,aes(x=Skewness,y=Kurtosis,color=Gen))+geom_point(aes(shape=Gen))+scale_x_continuous(limits=c(-1,2.5))+scale_y_continuous(limits=c(-1,8))+theme_bw()
@ 
\caption{Skewness and kurtosis for fitness in several generations of
  the Planet Wars problem. Different colors represent different generations.}
\label{fig:pw}
\end{figure}

The shape of the graph for the Planet Wars case study, shown in Figure
\ref{fig:pw} for two different generations, is different but shares
some similarities. The dispersion also decreases as evolution proceeds,
with the shape of the distribution becoming closer to the normal distribution in generation
50. Nevertheless, the initial kurtosis is quite high and values above 2 and
below 0 are found even later in the evolution. Noise is, thus, {\em
  noisy} and does not conform to a single shape, even less a normal
one; this implies that using a single statistical model to represent
noise will never be too close to reality, since the shapes of the
statistical distribution are, in general, away from the normal
distribution and then different among themselves even for a single
problem, that is, the shape of the statistical distribution of fitness
values in uncertain environments is, itself, uncertain or {\em noisy}.
% Alberto - I am not sure I understood this phrase...
% Explained a bit. Thanks for the suggestions - JJ

\begin{figure}[htb]
  \centering
<<pacman,cache=FALSE,echo=FALSE,warning=FALSE>>=
pm.s.k <- data.frame(Gen=character(), 
                  Skewness=character(),
                  Kurtosis=character(),
                  stringsAsFactors=FALSE)

for ( i in c(1,25,50)) {
    for ( j in unique(subset(pacman.data,Gen==i)$ID) ) {
        this.data <- subset(pacman.data,Gen==i & ID==j)$Fitness
        pm.s.k <- rbind( pm.s.k
                        , data.frame(Gen=paste("Gen",i)
                                     , Skewness=skewness(this.data)
                                     , Kurtosis=kurtosis(this.data)))
    }
}

ggplot(pm.s.k,aes(x=Skewness,y=Kurtosis,color=Gen))+geom_point(aes(shape=Gen))+scale_x_continuous(limits=c(-2,10))+scale_y_continuous(limits=c(-5,100))+theme_bw()
@ 
\caption{Skewness and kurtosis for fitness in several generations of
  the Ms. Pac-Man problem. Different colors represent different generations.}
\label{fig:pm}
\end{figure}

The graph for the third case study, ghosts in Ms. Pac-Man, is different in several
aspects, and is shown in Figure \ref{fig:pm}. First we have to take
into account, as explained in \ref{ss:pacman}, that differently from
the previous cases, the fitness for a ghost team is the maximum, not
an average of several values. This causes a curious behavior of
fitness: in the first generation, several individuals have {\em crisp}
values; however, this is less and less true, becoming more ``random'' as
generations proceed, that is, the set of values the fitness has got
begins to have many different values while in the first generations it
had one or a few. To put it in another words, in the first generation
the set of fitness measures could look like \texttt{\{x x x y x x x\}}. As
evolution proceeds, the measures in the set tend to be all different
% Alberto - I could not understand the last phrase ^_^;
% Hope it works now - JJ 
% Alberto - Yes, it works!
That is why the behavior shown in the graph is
completely different: distributions get increasingly asymmetric and
their shape grows further away from a normal distribution and closer to a
Beta distribution. Even if the trend is different from the other two
problems, the overall aspect is the same: there is no single
distribution that is able to describe the shape of fitness with an
uncertainty component, for all considered generations.

\begin{figure}[htb]
  \centering
<<starcraft,cache=FALSE,echo=FALSE,warning=FALSE>>=
sc.s.k <- data.frame(Gen=character(), 
                     Skewness=character(),
                     Kurtosis=character(),
                     stringsAsFactors=FALSE)

for ( i in c(1,15,30)) {
    for ( j in unique(subset(starcraft.data,Gen==i)$ID) ) {
        this.data <- subset(starcraft.data,Gen==i & ID==j)$Fitness
        sc.s.k <- rbind( sc.s.k
                      , data.frame(Gen=paste("Gen",i)
                                 , Skewness=skewness(this.data)
                                 , Kurtosis=kurtosis(this.data)))
    }
}

ggplot(sc.s.k,aes(x=Skewness,y=Kurtosis,color=Gen))+geom_point(aes(shape=Gen))+scale_x_continuous()+scale_y_continuous()+theme_bw()
@ 
\caption{Skewness and kurtosis for fitness in several generations of
  the StarCraft game. Different colors (or shades of gray) represent different generations.}
\label{fig:sc}
\end{figure}
%
%
\begin{figure}[htb]
  \centering
<<mlp,cache=FALSE,echo=FALSE,warning=FALSE>>=
mlp.s.k <- data.frame(Gen=character(), 
                      Skewness=character(),
                      Kurtosis=character(),
                      stringsAsFactors=FALSE)

for ( i in c(0,49,99)) {
    for ( j in unique(subset(mlp.data,Gen==i)$ID) ) {
        this.data <- subset(mlp.data,Gen==i & ID==j)$Fitness
        mlp.s.k <- rbind( mlp.s.k
                      , data.frame(Gen=paste("Gen",i)
                                 , Skewness=skewness(this.data)
                                 , Kurtosis=kurtosis(this.data)))
    }
}

ggplot(mlp.s.k,aes(x=Skewness,y=Kurtosis,color=Gen))+geom_point(aes(shape=Gen))+scale_x_continuous()+scale_y_continuous()+theme_bw()
@ 
\caption{Skewness and kurtosis for fitness in several generations of
  the MLP training problem. Different colors (or shades of gray)
  represent different generations.} 
\label{fig:mlp}
\end{figure}

The last game we have evaluated is StarCraft, with kurtosis and
skewness shown in Figure \ref{fig:sc}. In this case evaluation takes a
very long time, that is why only a few samples were available. That
might be the reason it is not quite clear if there is a trend. The
latest generation seems to be a bit closer to normal distribution, but
intermediate generations tend to have a high value. However, even if
values seem to be closer in generation 30, they are in some cases
positive and in other negative, indicating a distribution that is
flatter than the Gaussian and with the {\em bump} more loaded to the
right of the center. Once again, this proves that using non-parametric
methods like Wilcoxon are a better approach than using central
measures such as the average.

For the sake of completeness, we have also included in this paper a
problem that comes from a different area: genetic optimization of
neural networks. The skewness/kurtosis graph is included in Figure
\ref{fig:mlp}. Since the problem is completely different, the
distribution of the values is also completely different. For starters,
skewness tends to be negative, indicating distributions with a long
tail to the right; that means that, even if the value is centered
along a particular value, there are many values that are larger that
this central value. Once again, resampling cannot change the fact that
the average will not be an accurate description for the whole
data. Besides, values tend to get closer to 0 although in every generation 
there are values quite far away from them; e.g in the last generation, 
a neural net whose fitness distribution has kurtosis of 15, indicating a 
very sharp bump, is present, but it also has a low kurtosis of almost
-4 indicating a long tail to the right. 
The conclusion in this case is similar in the sense that values tend to change while they
keep away from a single kurtosis and skewness; even having less values than the latter 
if both of them are set to 0.

% ******************************************************************************%

\section{\uppercase{Conclusions}}
\label{sec:conclusion}

\noindent In this paper, we set out to study the statistical
distribution that best fits  the stochastic fitness values of single individuals 
in several case studies in the area of games; we have also included a
genetically optimized neural network for the sake of comparison.
Stochastic optimization algorithms applied to
MADE, Planet Wars, Ms. Pac-Man, and StarCraft exploit different ways to
compute the fitness values, but for all of them the fitness value is
not a fixed number but a random variable. This is also the case in
G-Prop, the genetically optimized multilayer perceptron. We
prove the hypothesis that not only noise does not follow the normal,
or Gaussian, distribution, or other centrally-distributed models such
as Cauchy, which have been used repeatedly in literature for
benchmarking selection methods in the presence of noise; but also
it does not follow a single, particular distribution even when considering a single
case study or a single generation.

%The study presented here proves that hypothesis. 
This conclusion follows from our study of the parameters of the
statistical variables that describe fitness. The best way to describe them is using two
parameters: kurtosis and skewness. These two parameters have been
computed and plotted for candidate solutions extracted from each one of the case studies, 
proving that not
only distributions are asymmetrical and not bell-shaped, but that their
shape changes within a single problem and in different stages of the
computation; this is in accordance with the conclusions reached by
Rattray and Shapiro in \cite{rattray1998noisy} for evolution of finite
populations in the presence of noise. In some case, like MADE, it seems clear that due to the
fact that averages are used as a representative for selection, 
individuals whose fitness is closer to a central shape are oversampled
and thus selected preferably, with almost-central individuals in the
latest stages being a consequence of this fact. In other cases, when
fitness is computed in a different way or selection takes another
form, the effect is exactly the opposite. At any rate, using averages
or other central measures like the median is discouraged 
after the study done in this paper since in many cases
and almost always in the early stages of the evolution, fitness, being
a random variable, does not pass a centrality test and it might not
even possess a reliable, that is, statistically significant,
average. A better way of comparing any fitness with 
uncertainty would be, as proposed by the authors, using non-parametric
tests such as the Wilcoxon test that impose a partial order on the
individuals \cite{merelo14:noisy}. This partial order can be used, in
several different ways, for selection. 

The fact that there is no single model representing the distribution
of fitness also implies that it is an error to use centrally
distributed random variables added to an actual fitness to test
operators and algorithms that operate in uncertainty. Either real
values should be used, such as the ones proposed above, or a
distribution with varying shape and symmetry such as Beta. However, in
this case we should take into account that ``true'' 
or ``crisp'' fitness {\em does not really exist}, so any modelization
of uncertain values that uses noise added to a fitness value is, in the
more general case, wrong, although it might still return correct results in some cases. 
If the fitness evaluation is expensive and tests have to be
performed for new selection operators, the best way to model uncertainty
would be to use {\em different} statistical models applied to every individual,
with different skewness and kurtosis. However, this would be only a
first-order approximation and it might still favor methods that use
averages. Following the model proposed by Jin \cite{jin2011surrogate}
for surrogate models, assuming normality in fitness will make
selectable some individuals that should not be. Assessing this error
and its impact on selection, and comparing how different methods, such
as the one based in statistical techniques and proposed previously,
reduce that error is also left as future work.

What remains to be done is to effectively apply Wilcoxon-based
comparisons to the case studies above. Since real-world case studies are computationally expensive to
evaluate, we plan to create a benchmark for problems with
uncertainty which reflects in the best possible way how fitness is
organized in a wide array of problems. In order to attain this goal, we will 
examine as many uncertain problems as possible, in the attempt to
deduce a model of noise what as general as possible.  


\section{\uppercase{Acknowledgements}}

This work has been supported in part by projects TIN2014-56494-C4-3-P (Spanish Ministry of Economy and Competitiveness), 
SPIP2014-01437 (Direcci{\'o}n General de Tr{\'a}fico), 
PRY142/14 (Fundaci{\'o}n P{\'u}blica Andaluza Centro de Estudios Andaluces en la IX Convocatoria de Proyectos de
Investigaci{\'o}n), 
PROY-PP2015-06 (Plan Propio 2015 UGR), 
and project CEI2015-MP-V17 of the Microprojects program 2015 from CEI
BioTIC Granada. We would like also to thank the anonymous reviewers
for this paper, for suggesting new readings and avenues of research. 

\bibliographystyle{splncs03}
\bibliography{geneura,GA-general,noisy}

\end{document}

%%% Local Variables:
%%% ispell-local-dictionary: "english"
%%% hunspell-local-dictionary: "english"
%%% End:

